{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:40:35.030691Z",
     "start_time": "2023-06-28T23:40:34.999482800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\tziam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import snscrape.modules.twitter as scrape_tweets\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collection of Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def collect_data():\n",
    "    location = '4.4149, -3.0424, 680km'\n",
    "    query = '(\"elevy\" OR \"e-levy\" OR \"increase OR VAT\" OR \"Financial OR sector OR levy\" OR \"income OR tax OR bill\" OR \"covid OR levy\" OR \"sustainability OR levy\" OR \"addo OR levy\" OR \"covid OR tax\" OR \"betting OR tax\" OR \"exercise OR duty OR bill\" OR \"electronic OR levy\") until:2023-06-20 since:2020-03-01 geocode:\"{}\"'.format(location)\n",
    "\n",
    "    tweets = []\n",
    "\n",
    "\n",
    "    for tweet in scrape_tweets.TwitterSearchScraper(query).get_items():\n",
    "        tweets.append([tweet.date, tweet.username, tweet.content])\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(tweets, columns=['Date', 'User', 'Tweet'])\n",
    "    df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:40:25.690893100Z",
     "start_time": "2023-06-28T23:40:25.674989600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing of Tweet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 36\u001B[0m\n\u001B[0;32m     32\u001B[0m     text \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(newline_pattern, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, text)\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m text\n\u001B[1;32m---> 36\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTweet\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTweet\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(clean_text)\n\u001B[0;32m     38\u001B[0m df\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Remove mentions\n",
    "    menttion_pattern = re.compile(r'@\\w+')\n",
    "    text = re.sub(menttion_pattern, '', text)\n",
    "\n",
    "    # Remove Hashtags\n",
    "    text = re.sub(r'#', '', text)\n",
    "\n",
    "    # Remove retweets\n",
    "    text = re.sub(r'RT[\\s]+', '', text)\n",
    "\n",
    "    # Remove urls\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002600-\\U000027BF\"  # miscellaneous symbols\n",
    "                               u\"\\U0001F910-\\U0001F9FF\"  # faces with accessories\n",
    "                               u\"\\u200d\"  # zero-width joiner\n",
    "                               u\"\\u2600-\\u26FF\\u2700-\\u27BF\"  # additional symbols\n",
    "                               u\"\\u3000-\\u303F\"  # punctuation symbols\n",
    "                               u\"\\uFE0F\"  # emoji variation selector\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = re.sub(emoji_pattern, '', text)\n",
    "\n",
    "    # Remove newlines\n",
    "    newline_pattern = re.compile(r'\\n')\n",
    "    text = re.sub(newline_pattern, '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "df['Tweet'] = df['Tweet'].apply(clean_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:43:51.242584700Z",
     "start_time": "2023-06-28T23:43:50.506981400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis using Textblob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read Data\n",
    "df = pd.read_csv('cleaned_tweet_2.csv')\n",
    "\n",
    "tweets = df['Tweet']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m sentiments \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m tweet \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtweets\u001B[49m:\n\u001B[0;32m      3\u001B[0m     blob \u001B[38;5;241m=\u001B[39m TextBlob(\u001B[38;5;28mstr\u001B[39m(tweet))  \u001B[38;5;66;03m# Convert tweet to string if it's not already\u001B[39;00m\n\u001B[0;32m      4\u001B[0m     polarity \u001B[38;5;241m=\u001B[39m blob\u001B[38;5;241m.\u001B[39msentiment\u001B[38;5;241m.\u001B[39mpolarity\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "sentiments = []\n",
    "for tweet in tweets:\n",
    "    blob = TextBlob(str(tweet))  # Convert tweet to string if it's not already\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0:\n",
    "        sentiment = 'Positive'\n",
    "    elif polarity < 0:\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "# Add the sentiments to the DataFrame\n",
    "data['Sentiment'] = sentiments"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:46:04.966702400Z",
     "start_time": "2023-06-28T23:46:04.913880500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the sentiment distribution\n",
    "sentiment_counts = data['Sentiment'].value_counts()\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values)\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis using Vader(NLTK)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:49:23.212055600Z",
     "start_time": "2023-06-28T23:49:23.161173400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Run polarity score on entire dataframe\u001B[39;00m\n\u001B[0;32m      2\u001B[0m res \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, row  \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39miterrows(), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(df)):\n\u001B[0;32m      4\u001B[0m     tweet \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTweet\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      5\u001B[0m     myid \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUser\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Run polarity score on entire dataframe\n",
    "res = {}\n",
    "for i, row  in tqdm(df.iterrows(), total=len(df)):\n",
    "    tweet = row['Tweet']\n",
    "    myid = row['User']\n",
    "    res[myid] = sia.polarity_scores(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:49:33.356634900Z",
     "start_time": "2023-06-28T23:49:33.294013300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m vaders \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(res)\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m      2\u001B[0m vaders \u001B[38;5;241m=\u001B[39m vaders\u001B[38;5;241m.\u001B[39mreset_index()\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUser\u001B[39m\u001B[38;5;124m'\u001B[39m})\n\u001B[1;32m----> 3\u001B[0m vaders \u001B[38;5;241m=\u001B[39m vaders\u001B[38;5;241m.\u001B[39mmerge(\u001B[43mdf\u001B[49m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'User'})\n",
    "vaders = vaders.merge(df, how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:50:38.767516100Z",
     "start_time": "2023-06-28T23:50:38.731771500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sentiment score and metadata\n",
    "vaders.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read Data\n",
    "df = pd.read_csv('Dataset\\\\cleaned_tweet_2.csv')\n",
    "\n",
    "tweets = df['Tweet']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis using Roberta"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Read Data\n",
    "df = pd.read_csv('Dataset\\\\cleaned_tweet_2.csv')\n",
    "\n",
    "tweets = df['Tweet']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:56:11.185786200Z",
     "start_time": "2023-06-28T23:56:11.154492600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:56:36.922628800Z",
     "start_time": "2023-06-28T23:56:29.598836Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "MODEL = f'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:56:54.550545Z",
     "start_time": "2023-06-28T23:56:45.016598900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Run on Roberta\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m encoded_text \u001B[38;5;241m=\u001B[39m tokenizer(\u001B[43mexample\u001B[49m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m output \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mencoded_text)\n\u001B[0;32m      4\u001B[0m scores \u001B[38;5;241m=\u001B[39m output[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "# Run on Roberta\n",
    "encoded_text = tokenizer(example, return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:56:59.753723600Z",
     "start_time": "2023-06-28T23:56:59.659401100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg': scores[0],\n",
    "        'roberta_neu': scores[1],\n",
    "        'roberta_pos': scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T23:57:14.570466400Z",
     "start_time": "2023-06-28T23:57:14.554848400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = {}\n",
    "try:\n",
    "    for i, row  in tqdm(df.iterrows(), total=len(df)):\n",
    "        tweet = row['Tweet']\n",
    "        myid = row['User']\n",
    "        vader_result = res[myid] = sia.polarity_scores(tweet)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "\n",
    "        roberta_result = polarity_scores_roberta(tweet)\n",
    "        both = {**vader_result, **roberta_result}\n",
    "        res[myid] = both\n",
    "except RuntimeError:\n",
    "    printf(f'Broke for id {myid}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  { 
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import snscrape.modules.twitter as snstwitter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collection of Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def collect_data():\n",
    "    location = '4.4149, -3.0424, 680km'\n",
    "    query = '(\"elevy\" OR \"e-levy\" OR \"increase OR VAT\" OR \"Financial OR sector OR levy\" OR \"income OR tax OR bill\" OR \"covid OR levy\" OR \"sustainability OR levy\" OR \"addo OR levy\" OR \"covid OR tax\" OR \"betting OR tax\" OR \"exercise OR duty OR bill\" OR \"electronic OR levy\") until:2023-06-20 since:2020-03-01 geocode:\"{}\"'.format(location)\n",
    "\n",
    "    tweets = []\n",
    "    limit = 200000\n",
    "\n",
    "\n",
    "    for tweet in snstwitter.TwitterSearchScraper(query).get_items():\n",
    "\n",
    "        # print(vars(tweet))\n",
    "        # break\n",
    "        if len(tweets) == limit:\n",
    "            break\n",
    "        else:\n",
    "            tweets.append([tweet.date, tweet.user.username, tweet.rawContent])\n",
    "\n",
    "    df = pd.DataFrame(tweets, columns=['Date', 'User', 'Tweet'])\n",
    "    print(df)\n",
    "\n",
    "    # Save tweets to CSV\n",
    "    df.to_csv('tweets.csv')\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Call collect_data function\n",
    "df = collect_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing of Tweet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweets.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_text(tweet_text):\n",
    "    # Remove mentions\n",
    "    mention_pattern = re.compile(r'@\\w+')\n",
    "    tweet_text = re.sub(mention_pattern, '', tweet_text)\n",
    "\n",
    "    # Remove Hashtags\n",
    "    tweet_text = re.sub(r'#', '', tweet_text)\n",
    "\n",
    "    # Remove retweets\n",
    "    tweet_text = re.sub(r'RT[\\s]+', '', tweet_text)\n",
    "\n",
    "    # Remove urls\n",
    "    tweet_text = re.sub(r'https?:\\/\\/\\S+', '', tweet_text)\n",
    "\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002600-\\U000027BF\"  # miscellaneous symbols\n",
    "                               u\"\\U0001F910-\\U0001F9FF\"  # faces with accessories\n",
    "                               u\"\\u200d\"  # zero-width joiner\n",
    "                               u\"\\u2600-\\u26FF\\u2700-\\u27BF\"  # additional symbols\n",
    "                               u\"\\u3000-\\u303F\"  # punctuation symbols\n",
    "                               u\"\\uFE0F\"  # emoji variation selector\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    tweet_text = re.sub(emoji_pattern, '', tweet_text)\n",
    "\n",
    "    # Remove newlines\n",
    "    newline_pattern = re.compile(r'\\n')\n",
    "    tweet_text = re.sub(newline_pattern, '', tweet_text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = word_tokenize(tweet_text)\n",
    "\n",
    "    # Get the list of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Remove stopwords from the tokens\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Join the filtered tokens back into a single string\n",
    "    filtered_tweet = ' '.join(filtered_tokens)\n",
    "\n",
    "    return filtered_tweet\n",
    "\n",
    "\n",
    "df['Tweet'] = df['Tweet'].apply(clean_text)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis using Textblob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read Data\n",
    "# df = pd.read_csv('cleaned_tweet_2.csv')\n",
    "\n",
    "tweets = df['Tweet']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "for tweet in tweets:\n",
    "    blob = TextBlob(str(tweet))  # Convert tweet to string if it's not already\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0:\n",
    "        sentiment = 'Positive'\n",
    "    elif polarity < 0:\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "# Add the sentiments to the DataFrame\n",
    "df['Sentiment'] = sentiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the sentiment distribution\n",
    "sentiment_counts = df['Sentiment'].value_counts()\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values)\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.savefig('plot.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis using Vader(NLTK)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "vaders_df = df.drop('Sentiment', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:37:12.552276300Z",
     "start_time": "2023-06-29T09:37:12.520972300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:37:13.017579100Z",
     "start_time": "2023-06-29T09:37:12.964410300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/4103 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6634561eeb2b4bae92b749e7d0d9791d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run polarity score on entire dataframe\n",
    "result = {}\n",
    "for i, row  in tqdm(vaders_df.iterrows(), total=len(df)):\n",
    "    tweet = row['Tweet']\n",
    "    myid = row['User']\n",
    "    result[myid] = sia.polarity_scores(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:37:17.398016100Z",
     "start_time": "2023-06-29T09:37:13.511984200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Store Vaders result in dataframe and merge with main dataframe\n",
    "vaders_res = pd.DataFrame(result).T\n",
    "vaders_res = vaders_res.reset_index().rename(columns={'index': 'User'})\n",
    "vaders_df = vaders_res.merge(vaders_df, how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:37:17.508934800Z",
     "start_time": "2023-06-29T09:37:17.446747800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "              User  neg    neu    pos  compound  Unnamed: 0  \\\n0    mrbones_evans  0.0  1.000  0.000    0.0000           0   \n1  Walkinonlinekms  0.0  0.892  0.108    0.3182           1   \n2  Walkinonlinekms  0.0  0.892  0.108    0.3182           8   \n3  Walkinonlinekms  0.0  0.892  0.108    0.3182          11   \n4  Walkinonlinekms  0.0  0.892  0.108    0.3182          12   \n\n                        Date  \\\n0  2023-06-03 15:08:40+00:00   \n1  2023-05-29 13:13:51+00:00   \n2  2023-05-20 15:17:56+00:00   \n3  2023-05-20 12:04:43+00:00   \n4  2023-05-20 09:19:51+00:00   \n\n                                               Tweet  \n0  means 1.5 % e-levy ’ took 12 months get gh74b ...  \n1  ’ lunch time ’ serving . SetGh370 . day delive...  \n2  ordered yet . Gh300 . Order today get today . ...  \n3  Keep orders coming . Set : Gh460 . Order today...  \n4  Good morning . ’ open . Keep orders coming . d...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>neg</th>\n      <th>neu</th>\n      <th>pos</th>\n      <th>compound</th>\n      <th>Unnamed: 0</th>\n      <th>Date</th>\n      <th>Tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mrbones_evans</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>2023-06-03 15:08:40+00:00</td>\n      <td>means 1.5 % e-levy ’ took 12 months get gh74b ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Walkinonlinekms</td>\n      <td>0.0</td>\n      <td>0.892</td>\n      <td>0.108</td>\n      <td>0.3182</td>\n      <td>1</td>\n      <td>2023-05-29 13:13:51+00:00</td>\n      <td>’ lunch time ’ serving . SetGh370 . day delive...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Walkinonlinekms</td>\n      <td>0.0</td>\n      <td>0.892</td>\n      <td>0.108</td>\n      <td>0.3182</td>\n      <td>8</td>\n      <td>2023-05-20 15:17:56+00:00</td>\n      <td>ordered yet . Gh300 . Order today get today . ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Walkinonlinekms</td>\n      <td>0.0</td>\n      <td>0.892</td>\n      <td>0.108</td>\n      <td>0.3182</td>\n      <td>11</td>\n      <td>2023-05-20 12:04:43+00:00</td>\n      <td>Keep orders coming . Set : Gh460 . Order today...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Walkinonlinekms</td>\n      <td>0.0</td>\n      <td>0.892</td>\n      <td>0.108</td>\n      <td>0.3182</td>\n      <td>12</td>\n      <td>2023-05-20 09:19:51+00:00</td>\n      <td>Good morning . ’ open . Keep orders coming . d...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment score and metadata\n",
    "vaders_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:37:19.474819500Z",
     "start_time": "2023-06-29T09:37:19.412866100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# pos_counts = vaders_df['pos'].value_counts()\n",
    "# sns.barplot(data=vaders_df, x='pos', y=pos_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:37:20.952092Z",
     "start_time": "2023-06-29T09:37:20.889150300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis using Roberta"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "roberta_df = df.drop('Sentiment', axis=1)\n",
    "roberta_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:37:40.399423600Z",
     "start_time": "2023-06-29T09:37:40.383804500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "MODEL = f'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T09:37:47.790502800Z",
     "start_time": "2023-06-29T09:37:41.161272400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get Polarity Scores using Roberta\n",
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg': scores[0],\n",
    "        'roberta_neu': scores[1],\n",
    "        'roberta_pos': scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/4103 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5fc264a20aa406e87169e5deedbd9ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roberta_res = {}\n",
    "try:\n",
    "    for i, row  in tqdm(df.iterrows(), total=len(df)):\n",
    "        tweet = row['Tweet']\n",
    "        myid = row['User']\n",
    "        vader_result = sia.polarity_scores(tweet)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "\n",
    "        roberta_result = polarity_scores_roberta(tweet)\n",
    "        both = {**vader_result, **roberta_result}\n",
    "        roberta_res[myid] = both\n",
    "except RuntimeError:\n",
    "    print(f'Broke for username: {myid}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T11:15:26.212971600Z",
     "start_time": "2023-06-29T10:50:27.103030500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(result).T\n",
    "results_df = result_df.reset_index().rename(columns={'index': 'User'})\n",
    "results_df = result_df.merge(vaders_df, how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare Score betweeen models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pairplot(data=result_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
